{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = '9LUbcPEw2ttjEclYHvSkwU1ES'\n",
    "CONSUMER_SECRET = '4jx0pCFviYbWj4GUFss8uUwLRfRPKJYGhVtyBFTd0NZ3O3gHgk'\n",
    "\n",
    "ACCESS_TOKEN = '735272926723772421-tNhzy6GlXO2gMPkQbjPXRAxBgz5jk5i'\n",
    "ACCESS_TOKEN_SECRET = 'qK0ABbGaqolY3baKB1soZN1ztSTtRQNnFQXbpzsL6WGo5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up API\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "# take into account rate limit\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get R tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results = 5000\n",
    "\n",
    "\"\"\"\n",
    "# create list to store tweets\n",
    "r_tweets = []\n",
    "# initialize tracker of last tweet we scraped\n",
    "max_id = 0\n",
    "# while we have less tweets than max_results\n",
    "while len(r_tweets) < max_results:\n",
    "    try:\n",
    "        r_search_results = tweepy.Cursor(api.search,\n",
    "                                         q='#rstats',\n",
    "                                         count=100,\n",
    "                                         lang='en',\n",
    "                                         tweet_mode='extended',\n",
    "                                         since_id = max_id).items()\n",
    "        for result in r_search_results:\n",
    "            r_tweets.append(result.full_text.encode('utf-8'))\n",
    "        max_id = len(r_tweets) - 1\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e.reason)\n",
    "        sleep(900)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Python Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "max_results = 10000\n",
    "# create list to store tweets\n",
    "python_tweets = []\n",
    "# initialize tracker of last tweet we scraped\n",
    "max_id = 0\n",
    "# while we have less tweets than max_results\n",
    "while len(python_tweets) < max_results:\n",
    "    try:\n",
    "        p_search_results = tweepy.Cursor(api.search,\n",
    "                                         q='#pydata',\n",
    "                                         count=100,\n",
    "                                         lang='en',\n",
    "                                         tweet_mode='extended',\n",
    "                                         since_id = max_id).items()\n",
    "        for result in p_search_results:\n",
    "            python_tweets.append(result.full_text.encode('utf-8'))\n",
    "        max_id = len(python_tweets) - 1\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e.reason)\n",
    "        sleep(900)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Julia Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "max_results = 10000\n",
    "# create list to store tweets\n",
    "julia_tweets = []\n",
    "# initialize tracker of last tweet we scraped\n",
    "max_id = 0\n",
    "# while we have less tweets than max_results\n",
    "while len(julia_tweets) < max_results:\n",
    "    try:\n",
    "        j_search_results = tweepy.Cursor(api.search,\n",
    "                                         q='#julialang',\n",
    "                                         count=100,\n",
    "                                         lang='en',\n",
    "                                         tweet_mode='extended',\n",
    "                                         since_id = max_id).items()\n",
    "        for result in j_search_results:\n",
    "            julia_tweets.append(result.full_text.encode('utf-8'))\n",
    "        max_id = len(julia_tweets) - 1\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e.reason)\n",
    "        sleep(900)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Open/create a file to append data to\n",
    "csvFile = open('tweet_results.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvWriter.writerow(['language', 'tweet'])\n",
    "\n",
    "for tweet in r_tweets:\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow(['R', tweet])\n",
    "    \n",
    "for tweet in python_tweets:\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow(['Python', tweet])\n",
    "    \n",
    "for tweet in julia_tweets:\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow(['Julia', tweet])\n",
    "    \n",
    "csvFile.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Julia and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from datetime import date\n",
    "today = date.today().strftime(\"%d-%m-%Y\")\n",
    "today = \"11-21-2019\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store tweets\n",
    "python_tweets = []\n",
    "\n",
    "p_search_results = tweepy.Cursor(api.search,\n",
    "                                 q='#pydata',\n",
    "                                 count=500,\n",
    "                                 lang='en',\n",
    "                                 tweet_mode='extended').items()\n",
    "for result in p_search_results:\n",
    "        python_tweets.append(result.full_text.encode('utf-8'))\n",
    "        \n",
    "p_search_results = tweepy.Cursor(api.search,\n",
    "                                     q='#pystats',\n",
    "                                     count=100,\n",
    "                                     lang='en',\n",
    "                                     tweet_mode='extended').items()\n",
    "for result in p_search_results:\n",
    "        python_tweets.append(result.full_text.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store tweets\n",
    "julia_tweets = []\n",
    "# while we have less tweets than max_results\n",
    "j_search_results = tweepy.Cursor(api.search,\n",
    "                                         q='#julialang',\n",
    "                                         count=500,\n",
    "                                         lang='en',\n",
    "                                         tweet_mode='extended').items()\n",
    "for result in j_search_results:\n",
    "    julia_tweets.append(result.full_text.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open/create a file to append data to\n",
    "csvFile = open('tweet_results.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "    \n",
    "for tweet in python_tweets:\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow(['Python', tweet])\n",
    "    \n",
    "for tweet in julia_tweets:\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow(['Julia', tweet])\n",
    "    \n",
    "csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
